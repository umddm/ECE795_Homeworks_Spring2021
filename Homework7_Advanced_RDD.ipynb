{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework7_Advanced_RDD.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FugKl36uD_X"
      },
      "source": [
        "# ECE795 Advanced Big Data Analytics Homework 7 (Due 04/20, 60 Total Points)\n",
        "\n",
        "Please create a Dataproc cluster in Google Cloud Platform, access the master node using ssh, and answer the following questions using beeline.\n",
        "\n",
        "In your answers, please provide necessary contents, including commands, screenshots and the outputs of the commands.\n",
        "\n",
        "## Hive and Data Partitioning in GCP\n",
        "\n",
        "Note: in the beeline environment in GCP, all the column names should be quoted by \\`\\` as the valid syntax. An example query can be found in the following."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-G2t1rAhFSHc"
      },
      "source": [
        "CREATE EXTERNAL TABLE jobs (\n",
        "   `id` INT, \n",
        "   `title` STRING, \n",
        "   `salary` INT, \n",
        "   `posted` TIMESTAMP\n",
        " )\n",
        " ROW FORMAT DELIMITED\n",
        " FIELDS TERMINATED BY ',';"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5md8JSmxmBC"
      },
      "source": [
        "### (5 points) Q1. Please describe three commands available in the beeline and explain their functionality."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0edJYz63x69n"
      },
      "source": [
        "# Your answer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81kUtuf9xoCz"
      },
      "source": [
        "### (5 points) Q2. Please download `data.csv` file from Github and put it in HDFS (any path that you want but `data.csv` should be the only file in the path).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6efyFJXDx89I"
      },
      "source": [
        "# Your answer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxwUcoHCxptK"
      },
      "source": [
        "### (10 points) Q3. To connect to the Hive using beeline, please use the provided command and enter it in the terminal of the master node. In beeline environment, please create a table for the data in data.csv using approriate schema.\n",
        "\n",
        "The names of the columns are `id`, `date`, `currency`, and `rate`. The table records the currency exchange rate for several years."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7iMwjeXBHoP"
      },
      "source": [
        "beeline -u \"jdbc:hive2://localhost:10000\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBE2kLxvx9eF"
      },
      "source": [
        "# Your answer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av2wj8lnyA9V"
      },
      "source": [
        "### (10 points) Q4. Please show the proof that the data in `data.csv` has been loaded to the created table.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52g12FjR0mmx"
      },
      "source": [
        "# Your answer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jewO62RE0nvz"
      },
      "source": [
        "### (10 points) Q5. Please use Hive SQL to find the currency with the highest rate between 2000 and 2008."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyBujQEZ02Zm"
      },
      "source": [
        "# Your answer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaxsqO240377"
      },
      "source": [
        "### (10 points) Q6. Please create a table of the same data with data partition using `currency` as the key."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1Hu1NwF1HsW"
      },
      "source": [
        "# Your answer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0lnp6Kn1Imu"
      },
      "source": [
        "### (10 points) Q7. Please discuss the advantages and disadvantages of using (1) `currency`, (2) `date`, and (3) `currency` and `date`, as the key of data partitioning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67jnDbAL1QHj"
      },
      "source": [
        "# Your answer"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}